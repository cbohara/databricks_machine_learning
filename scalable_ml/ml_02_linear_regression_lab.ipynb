{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c680c716-00c4-4006-9250-6aaef50d79cb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12226559-dd65-446e-9fbc-7c012f2f8dfe",
     "showTitle": false,
     "title": "--i18n-45bb1181-9fe0-4255-b0f0-b42637fc9591"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "#Linear Regression Lab\n",
    "\n",
    "In the previous lesson, we predicted price using just one variable: bedrooms. Now, we want to predict price given a few other features.\n",
    "\n",
    "Steps:\n",
    "1. Use the features: **`bedrooms`**, **`bathrooms`**, **`bathrooms_na`**, **`minimum_nights`**, and **`number_of_reviews`** as input to your VectorAssembler.\n",
    "1. Build a Linear Regression Model\n",
    "1. Evaluate the **`RMSE`** and the **`R2`**.\n",
    "\n",
    "## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Learning Objectives:<br>\n",
    "\n",
    "By the end of this lab, you should be able to;\n",
    "\n",
    "* Build a linear regression model with multiple features\n",
    "* Compute various metrics to evaluate goodness of fit\n",
    "* Explain Spark MLâ€™s approach to solve distributed linear regression problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd5ca5af-beb4-4be0-9680-5964ee99676a",
     "showTitle": false,
     "title": "--i18n-0b2213da-e388-4faf-aa92-3315d94ee689"
    }
   },
   "source": [
    "## Lab Setup\n",
    "\n",
    "The first thing we're going to do is to **run setup script**. This script will define the required configuration variables that are scoped to each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9d70307-7665-4457-9b44-44d6f95ceccb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nPython interpreter will be restarted.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the learning environment:\n| No action taken\n\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/scalable-machine-learning-with-apache-spark/v02\"\n\nValidating the locally installed datasets:\n| listing local files...(3 seconds)\n| validation completed...(3 seconds total)\n\nCreating & using the schema \"charlie_ohara_4mi2_da_sml\" in the catalog \"hive_metastore\"...(1 seconds)\n\nPredefined tables in \"charlie_ohara_4mi2_da_sml\":\n| -none-\n\nPredefined paths variables:\n| DA.paths.working_dir: dbfs:/mnt/dbacademy-users/charlie.ohara@standard.ai/scalable-machine-learning-with-apache-spark\n| DA.paths.user_db:     dbfs:/mnt/dbacademy-users/charlie.ohara@standard.ai/scalable-machine-learning-with-apache-spark/database.db\n| DA.paths.datasets:    dbfs:/mnt/dbacademy-datasets/scalable-machine-learning-with-apache-spark/v02\n\nSetup completed (14 seconds)\n"
     ]
    }
   ],
   "source": [
    "%run \"../Includes/Classroom-Setup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27a750c4-c9ed-4f4e-b66c-77689a2523fa",
     "showTitle": false,
     "title": "--i18n-6b124bfe-8486-4607-b911-9fc433159633"
    }
   },
   "source": [
    "\n",
    "## Load Dataset and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a59fcdc-a10a-47e5-a205-9bd8fc9f9d67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbfs:/mnt/dbacademy-datasets/scalable-machine-learning-with-apache-spark/v02\n"
     ]
    }
   ],
   "source": [
    "print(DA.paths.datasets)\n",
    "file_path = f\"{DA.paths.datasets}/airbnb/sf-listings/sf-listings-2019-03-06-clean.delta/\"\n",
    "airbnb_df = spark.read.format(\"delta\").load(file_path)\n",
    "train_df, test_df = airbnb_df.randomSplit([.8, .2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c1a89f6-19c2-415e-b440-608b9b3a5111",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# merges multiple columns into a vector column to reduce the noise and make it easier for the model to process\n",
    "vec_assembler = VectorAssembler(\n",
    "  inputCols=[\"bedrooms\", \"bathrooms\", \"bathrooms_na\", \"minimum_nights\", \"number_of_reviews\"],\n",
    "  outputCol=\"features\"\n",
    ")\n",
    "\n",
    "vtrain_df = vec_assembler.transform(train_df)\n",
    "vtest_df = vec_assembler.transform(test_df)\n",
    "\n",
    "# generate a model using fit() method to fit on the training data \n",
    "lr_model = LinearRegression(labelCol=\"price\").fit(vtrain_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3624719f-b567-40e0-8f1e-6ede84e5a859",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# this will add a column to the data frame with the predictions \n",
    "pred_df = lr_model.transform(vtest_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1be05bed-9bd8-400f-adb9-b7a1fd230990",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 146.66557395182022\nR2 is 0.3256757861255597\n"
     ]
    }
   ],
   "source": [
    "regression_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"price\", metricName=\"rmse\")\n",
    "rmse = regression_evaluator.evaluate(pred_df)\n",
    "\n",
    "regression_evaluator.setMetricName(\"r2\").evaluate(pred_df)\n",
    "r2 = regression_evaluator.evaluate(pred_df)\n",
    "print(f\"RMSE is {rmse}\")\n",
    "print(f\"R2 is {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4b5c303-02ac-410f-be7d-0b286c1c7a40",
     "showTitle": false,
     "title": "--i18n-25a260af-8d6e-4897-8228-80074c4f1d64"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Examine the coefficients for each of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "295a81ab-6515-43fb-8378-bd94060ce60d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedrooms 115.67218110629405\nbathrooms 15.32773278579738\nbathrooms_na -59.66329665713675\nminimum_nights -0.5012697007581\nnumber_of_reviews -0.29570073989207135\nintercept: 61.14012549013659\n"
     ]
    }
   ],
   "source": [
    "# the higher the coefficient value, the greater the prediction price \n",
    "# the lower the coefficient value, the lower the prediction price\n",
    "# y = mx + b  (m is the coefficient)\n",
    "for col, coef in zip(vec_assembler.getInputCols(), lr_model.coefficients):\n",
    "    print(col, coef)\n",
    "  \n",
    "print(f\"intercept: {lr_model.intercept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31204f25-324f-4fa9-a2e0-a11969927e7e",
     "showTitle": false,
     "title": "--i18n-218d51b8-7453-4f6a-8965-5a60e8c80eaf"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## Distributed Setting\n",
    "\n",
    "Although we can quickly solve for the parameters when the data is small, the closed form solution doesn't scale well to large datasets. \n",
    "\n",
    "Spark uses the following approach to solve a linear regression problem:\n",
    "\n",
    "* First, Spark tries to use matrix decomposition to solve the linear regression problem. \n",
    "* If it fails, Spark then uses <a href=\"https://spark.apache.org/docs/latest/ml-advanced.html#limited-memory-bfgs-l-bfgs\" target=\"_blank\">L-BFGS</a> to solve for the parameters. L-BFGS is a limited-memory version of BFGS that is particularly suited to problems with very large numbers of variables. The <a href=\"https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm\" target=\"_blank\">BFGS</a> method belongs to <a href=\"https://en.wikipedia.org/wiki/Quasi-Newton_method\" target=\"_blank\">quasi-Newton methods</a>, which are used to either find zeroes or local maxima and minima of functions iteratively. \n",
    "\n",
    "If you are interested in how linear regression is implemented in the distributed setting and bottlenecks, check out these lecture slides:\n",
    "* <a href=\"https://files.training.databricks.com/static/docs/distributed-linear-regression-1.pdf\" target=\"_blank\">distributed-linear-regression-1</a>\n",
    "* <a href=\"https://files.training.databricks.com/static/docs/distributed-linear-regression-2.pdf\" target=\"_blank\">distributed-linear-regression-2</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9e2c93d-de7e-488e-acd5-d2077af5be74",
     "showTitle": false,
     "title": "--i18n-f3e00d9e-3b02-44cf-87b7-20b54ba350c9"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Yikes! We built a pretty bad model. In the next notebook, we will see how we can further improve upon our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8ba0f67-bc0f-4196-a905-5285bbef01ed",
     "showTitle": false,
     "title": "--i18n-a2c7fb12-fd0b-493f-be4f-793d0a61695b"
    }
   },
   "source": [
    "\n",
    "## Classroom Cleanup\n",
    "\n",
    "Run the following cell to remove lessons-specific assets created during this lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45b81099-2401-4a82-9439-5036ac9c0693",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the learning environment:\n| dropping the schema \"charlie_ohara_4mi2_da_sml\"...(1 seconds)\n| removing the working directory \"dbfs:/mnt/dbacademy-users/charlie.ohara@standard.ai/scalable-machine-learning-with-apache-spark\"...(0 seconds)\n\nValidating the locally installed datasets:\n| listing local files...(3 seconds)\n| validation completed...(3 seconds total)\n"
     ]
    }
   ],
   "source": [
    "DA.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82b7c74d-f41c-42d1-a38a-96868f2861aa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "&copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "ml_02_linear_regression_lab",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
